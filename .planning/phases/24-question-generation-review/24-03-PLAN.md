---
phase: 24-question-generation-review
plan: 03
type: execute
wave: 3
depends_on: ["24-02"]
files_modified:
  - backend/src/scripts/content-generation/curate-fremont-questions.ts
autonomous: false

must_haves:
  truths:
    - "User has spot-checked a sample of 20-30 questions for cultural sensitivity"
    - "Ohlone questions use present tense ('have lived here') not past tense"
    - "Afghan-American/Little Kabul questions focus on cultural heritage, not refugee narrative"
    - "Tesla/NUMMI questions are civic-only (no products, no Elon Musk)"
    - "Mission San Jose questions disambiguate between historic mission and modern district"
    - "Final curated set has 95-105 active questions"
    - "Topic distribution balanced across 8 categories within targets"
    - "Difficulty distribution approximately 40/40/20"
    - "Time-sensitive questions have correct expiration timestamps"
    - "All final questions include explanations with 'According to' citations"
  artifacts:
    - path: "database: questions table"
      provides: "95-105 active Fremont questions ready for gameplay"
    - path: "backend/src/scripts/content-generation/curate-fremont-questions.ts"
      provides: "Curation script for selecting best ~100 from pool"
  key_links:
    - from: "curate-fremont-questions.ts"
      to: "database questions table"
      via: "UPDATE status from draft to active for curated questions"
      pattern: "status.*active"
    - from: "database questions"
      to: "collection_questions"
      via: "fremont-ca collection linkage"
      pattern: "fremont-ca"
---

<objective>
Spot-check questions for cultural sensitivity, curate from ~130 pool to ~100 best questions, and activate the final set.

Purpose: Automated quality rules catch structural issues but cannot judge cultural sensitivity (Ohlone framing, Afghan-American representation, Tesla civic angle). Human spot-checking a sample of 20-30 questions ensures the generated content meets Fremont's specific sensitivity requirements. After review, curate the best ~100 questions based on quality, topic balance, difficulty distribution, and sensitivity, then activate them for gameplay.

Output: 95-105 active, quality-validated Fremont questions ready for Phase 25 activation.
</objective>

<execution_context>
@C:\Users\Chris\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Chris\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/24-question-generation-review/24-CONTEXT.md
@.planning/phases/24-question-generation-review/24-02-SUMMARY.md

@backend/src/scripts/content-generation/locale-configs/fremont-ca.ts
@backend/src/scripts/content-generation/utils/seed-questions.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extract spot-check sample and build curation script</name>
  <files>
    backend/src/scripts/content-generation/curate-fremont-questions.ts
  </files>
  <action>
  Create a curation script at `backend/src/scripts/content-generation/curate-fremont-questions.ts` that:

  **1. Extracts a stratified spot-check sample:**
  - Query all draft Fremont questions from database
  - Select 3-4 random questions from each of the 8 topic categories (24-32 total)
  - Prioritize including questions from sensitive topics: civic-history (for Ohlone), landmarks-culture (for Little Kabul, Mission San Jose), budget-finance (for Tesla/NUMMI)
  - Print each sample question with: externalId, text, all 4 options, correct answer, explanation, difficulty, topicCategory, source URL
  - Print sensitivity checklist per topic for the reviewer

  **2. Curates the full pool to ~100:**
  - Accept `--mode sample` to output the spot-check sample
  - Accept `--mode curate` to perform curation
  - Accept `--mode activate` to change status from draft to active

  Curation logic (in `--mode curate`):
  - Group questions by topicCategory
  - For each topic, score questions on:
    - Engagement: Penalize "In what year" questions (-20), phone numbers (-50)
    - Source quality: .gov (+10), .edu (+5)
    - Explanation quality: longer than 200 chars (+10)
    - Difficulty bonus: medium (+10), hard (+15) (to counter AI's easy-skew)
    - Freshness: has expiresAt (+15)
  - Select top N per topic matching distribution targets from fremont-ca.ts
  - Print curation report: kept/dropped per topic, total kept, difficulty breakdown
  - Write curated external IDs to stdout for review

  Activation logic (in `--mode activate`):
  - Accept `--ids fre-001,fre-002,...` or `--all-curated` flag
  - UPDATE questions SET status='active' WHERE externalId IN (ids) AND collection is fremont-ca
  - Print activation count

  **Usage:**
  ```bash
  # Step 1: Get spot-check sample
  npx tsx src/scripts/content-generation/curate-fremont-questions.ts --mode sample

  # Step 2: After human review, curate
  npx tsx src/scripts/content-generation/curate-fremont-questions.ts --mode curate

  # Step 3: After confirming curation, activate
  npx tsx src/scripts/content-generation/curate-fremont-questions.ts --mode activate --all-curated
  ```
  </action>
  <verify>
  ```bash
  cd backend && npx tsc --noEmit
  ```

  Run the sample mode to verify it produces output:
  ```bash
  cd backend && npx tsx src/scripts/content-generation/curate-fremont-questions.ts --mode sample
  ```
  Should print 24-32 questions with sensitivity checklists.
  </verify>
  <done>
  - Curation script created with sample, curate, and activate modes
  - Sample mode outputs stratified random sample with sensitivity checklists
  - Curate mode scores and selects best ~100 questions
  - Activate mode changes status from draft to active
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
  A spot-check sample of 20-30 Fremont questions stratified across 8 topic categories, with emphasis on sensitive topics (Ohlone/Indigenous, Afghan-American/Little Kabul, Tesla/NUMMI, Mission San Jose).

  The sample was extracted by running:
  ```bash
  cd backend && npx tsx src/scripts/content-generation/curate-fremont-questions.ts --mode sample
  ```
  </what-built>
  <how-to-verify>
  Review the printed sample questions. For each question, check:

  **All questions:**
  1. Clean & direct tone (clear, not stuffy, not trying to be funny)
  2. Explanation is informative and neutral with "According to..." citation
  3. Four plausible answer options (no obviously wrong throwaway answers)
  4. Correct answer is actually correct

  **Civic History questions (check for Ohlone framing):**
  - Uses present tense for Ohlone presence ("have lived here" not "lived here")
  - No romanticization of mission system
  - Five-town consolidation names all five towns when relevant

  **Landmarks & Culture questions (check for sensitivity):**
  - Afghan-American/Little Kabul: cultural heritage focus, not refugee narrative
  - Mission San Jose: explicitly disambiguated (historic vs district)
  - Diversity: celebrates institutions/events, not census statistics

  **Budget & Finance questions (check for Tesla/NUMMI):**
  - Civic angles only (zoning, jobs, tax revenue)
  - No Tesla products, no Elon Musk, no corporate strategy

  **If sample looks good:** Type "approved" to continue to curation
  **If issues found:** Describe the issues (e.g., "Question fre-042 uses past tense for Ohlone, question fre-089 asks about Tesla products"). Claude will fix or regenerate affected questions before proceeding.
  </how-to-verify>
  <resume-signal>Type "approved" to proceed to curation, or describe specific issues to fix</resume-signal>
</task>

<task type="auto">
  <name>Task 3: Curate to ~100 and activate final question set</name>
  <files>
    database: questions table (status updated)
  </files>
  <action>
  After human approval of the spot-check sample, run the curation and activation:

  **Step 1: Run curation to select best ~100:**
  ```bash
  cd backend
  npx tsx src/scripts/content-generation/curate-fremont-questions.ts --mode curate
  ```

  Review the curation report output:
  - Each topic should have approximately the target count from fremont-ca.ts
  - civic-history: ~20, landmarks-culture: ~18, budget-finance: ~12, others: ~10 each
  - Total curated: 95-105 questions (don't force exactly 100)
  - Difficulty balance: approximately 40% easy, 40% medium, 20% hard

  **Step 2: If curation looks good, activate the curated questions:**
  ```bash
  npx tsx src/scripts/content-generation/curate-fremont-questions.ts --mode activate --all-curated
  ```

  **Step 3: Verify final state:**
  ```bash
  npx tsx -e "
    import 'dotenv/config';
    import { db } from './src/db/index.js';
    import { sql } from 'drizzle-orm';

    // Count active questions
    const activeResult = await db.execute(sql\`
      SELECT COUNT(*) as count FROM civic_trivia.questions q
      JOIN civic_trivia.collection_questions cq ON q.id = cq.question_id
      JOIN civic_trivia.collections c ON cq.collection_id = c.id
      WHERE c.slug = 'fremont-ca' AND q.status = 'active'
    \`);
    console.log('Active Fremont questions:', activeResult.rows[0].count);

    // Topic distribution of active questions
    const topicResult = await db.execute(sql\`
      SELECT q.subcategory, COUNT(*) as count
      FROM civic_trivia.questions q
      JOIN civic_trivia.collection_questions cq ON q.id = cq.question_id
      JOIN civic_trivia.collections c ON cq.collection_id = c.id
      WHERE c.slug = 'fremont-ca' AND q.status = 'active'
      GROUP BY q.subcategory ORDER BY count DESC
    \`);
    console.log('\\nTopic distribution:');
    for (const row of topicResult.rows) {
      console.log(\`  \${row.subcategory}: \${row.count}\`);
    }

    // Difficulty distribution
    const diffResult = await db.execute(sql\`
      SELECT q.difficulty, COUNT(*) as count
      FROM civic_trivia.questions q
      JOIN civic_trivia.collection_questions cq ON q.id = cq.question_id
      JOIN civic_trivia.collections c ON cq.collection_id = c.id
      WHERE c.slug = 'fremont-ca' AND q.status = 'active'
      GROUP BY q.difficulty
    \`);
    console.log('\\nDifficulty distribution:');
    for (const row of diffResult.rows) {
      console.log(\`  \${row.difficulty}: \${row.count}\`);
    }

    // Expiration timestamp check
    const expiresResult = await db.execute(sql\`
      SELECT COUNT(*) as count FROM civic_trivia.questions q
      JOIN civic_trivia.collection_questions cq ON q.id = cq.question_id
      JOIN civic_trivia.collections c ON cq.collection_id = c.id
      WHERE c.slug = 'fremont-ca' AND q.status = 'active' AND q.expires_at IS NOT NULL
    \`);
    console.log('\\nQuestions with expiration timestamps:', expiresResult.rows[0].count);

    process.exit(0);
  "
  ```

  **If any topic has 0 active questions:** Generate supplemental questions for that topic using the generation script with `--batch` flag targeting that specific topic range.

  **If total is below 95:** Consider reducing curation strictness or generating more questions for under-represented topics.

  **Handle sensitivity issues from spot-check (if any were flagged):**
  If the human reviewer flagged specific questions during the checkpoint:
  1. Delete flagged questions from database
  2. Regenerate replacements for that topic with enhanced sensitivity instructions
  3. Re-validate and seed replacements
  4. Include replacements in the curated set
  </action>
  <verify>
  - Active Fremont questions count: 95-105
  - All 8 topic categories have active questions
  - No topic category has fewer than 8 active questions
  - Difficulty distribution within acceptable range (30-50% easy, 30-50% medium, 15-25% hard)
  - At least some questions have expiration timestamps (for elected officials)
  - All active questions have "According to" in their explanations
  </verify>
  <done>
  - 95-105 active Fremont questions in the database
  - Topic distribution balanced across 8 categories matching targets
  - Difficulty distribution approximately 40/40/20 easy/medium/hard
  - Cultural sensitivity verified by human spot-check
  - Time-sensitive questions have expiration timestamps
  - All questions include cited explanations
  - Remaining draft questions left in database (can be reviewed/activated later)
  - Ready for Phase 25 (Image, Seed & Activation)
  </done>
</task>

</tasks>

<verification>
- Active Fremont question count between 95 and 105
- All 8 topic categories represented with at least 8 questions each
- civic-history has ~20, landmarks-culture has ~18 (the heavy categories)
- Difficulty distribution approximately 40% easy, 40% medium, 20% hard
- Human verified cultural sensitivity via spot-check sample
- Time-sensitive questions have expiration timestamps
- All questions have "According to" citations in explanations
- No blocking quality violations in active questions
</verification>

<success_criteria>
- 95-105 active, quality-validated Fremont questions ready for gameplay
- Cultural sensitivity verified by human for Ohlone, Afghan-American, Tesla/NUMMI, Mission San Jose content
- Topic and difficulty distribution balanced per requirements
- Expiration timestamps set for time-sensitive questions (elected officials)
- Phase 24 success criteria met: questions ready for Phase 25 activation
</success_criteria>

<output>
After completion, create `.planning/phases/24-question-generation-review/24-03-SUMMARY.md`
</output>
