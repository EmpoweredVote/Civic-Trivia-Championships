---
phase: 17-community-content-generation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/src/scripts/content-generation/anthropic-client.ts
  - backend/src/scripts/content-generation/question-schema.ts
  - backend/src/scripts/content-generation/prompts/system-prompt.ts
  - backend/src/scripts/content-generation/locale-configs/bloomington-in.ts
  - backend/src/scripts/content-generation/locale-configs/los-angeles-ca.ts
  - backend/src/scripts/content-generation/rag/fetch-sources.ts
  - backend/src/scripts/content-generation/rag/parse-sources.ts
  - backend/src/scripts/content-generation/utils/seed-questions.ts
  - backend/src/scripts/content-generation/generate-locale-questions.ts
autonomous: true

must_haves:
  truths:
    - "Generation script can be invoked with a locale argument and produces structured question output"
    - "Source fetcher downloads .gov/.edu pages and saves clean text files for RAG"
    - "Zod schema validates generated questions match the database schema exactly"
    - "Locale configs are reusable templates that can be extended for future cities"
  artifacts:
    - path: "backend/src/scripts/content-generation/generate-locale-questions.ts"
      provides: "Main generation script entry point"
      contains: "generateLocaleQuestions"
    - path: "backend/src/scripts/content-generation/question-schema.ts"
      provides: "Zod validation schema for generated questions"
      contains: "QuestionSchema"
    - path: "backend/src/scripts/content-generation/locale-configs/bloomington-in.ts"
      provides: "Bloomington locale configuration with topics and source URLs"
      contains: "bloomingtonConfig"
    - path: "backend/src/scripts/content-generation/locale-configs/los-angeles-ca.ts"
      provides: "LA locale configuration with topics and source URLs"
      contains: "losAngelesConfig"
    - path: "backend/src/scripts/content-generation/rag/fetch-sources.ts"
      provides: "Source document fetcher and HTML-to-text parser"
      contains: "fetchSources"
    - path: "backend/src/scripts/content-generation/utils/seed-questions.ts"
      provides: "Database seeder for generated questions with draft status"
      contains: "seedQuestionBatch"
  key_links:
    - from: "generate-locale-questions.ts"
      to: "locale-configs/*.ts"
      via: "dynamic import based on locale argument"
      pattern: "import.*locale-configs"
    - from: "generate-locale-questions.ts"
      to: "anthropic-client.ts"
      via: "client instance for API calls"
      pattern: "client\\.messages\\.create"
    - from: "utils/seed-questions.ts"
      to: "backend/src/db/schema.ts"
      via: "drizzle insert into questions + collectionQuestions"
      pattern: "db\\.insert\\(questions\\)"
---

<objective>
Build the reusable content generation tooling infrastructure for locale-specific civic trivia question generation.

Purpose: Creates the foundation scripts that Plans 02 and 03 will use to generate Bloomington and LA questions. Designed for reuse with future locales.
Output: Complete generation pipeline — locale configs, Anthropic client with prompt caching, Zod validation schema, RAG source fetcher, question seeder, and main orchestrator script.
</objective>

<execution_context>
@C:\Users\Chris\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Chris\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/17-community-content-generation/17-RESEARCH.md
@.planning/phases/17-community-content-generation/17-CONTEXT.md
@backend/src/db/schema.ts
@backend/src/db/index.ts
@backend/src/db/seed/seed.ts
@backend/src/db/seed/collections.ts
@backend/src/scripts/generateLearningContent.ts
@backend/package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install dependencies and create core utilities</name>
  <files>
    backend/package.json
    backend/src/scripts/content-generation/anthropic-client.ts
    backend/src/scripts/content-generation/question-schema.ts
  </files>
  <action>
    1. Install new dependencies in backend/:
       ```bash
       cd backend && npm install zod cheerio p-limit
       ```
       Note: @anthropic-ai/sdk is already installed as devDependency. zod-to-json-schema is NOT needed — use Anthropic's native tool_use pattern with JSON schema directly, or parse response text with Zod.

    2. Create `anthropic-client.ts`:
       - Import Anthropic from '@anthropic-ai/sdk'
       - Import 'dotenv/config' at top (follow pattern from seed.ts and generateLearningContent.ts)
       - Create and export configured client: `new Anthropic({ maxRetries: 3, timeout: 120000 })`
       - Export MODEL constant as 'claude-sonnet-4-5'
       - SDK auto-detects ANTHROPIC_API_KEY from environment

    3. Create `question-schema.ts`:
       - Define Zod schema matching the database questions table from schema.ts:
         - externalId: string matching /^[a-z]{3}-\d{3}$/ (e.g., "bli-001" for Bloomington, "lac-001" for LA)
         - text: string (10-300 chars)
         - options: array of exactly 4 strings (1-200 chars each)
         - correctAnswer: number 0-3
         - explanation: string (20-500 chars) — must contain "According to" citation pattern
         - difficulty: enum 'easy' | 'medium' | 'hard'
         - topicCategory: string (the locale-specific topic slug)
         - source: object { name: string, url: string (must be valid URL) }
         - expiresAt: string datetime ISO 8601 or null (for elected official questions)
       - Define BatchSchema: object with `questions` array of 15-30 QuestionSchema items
       - Export both schemas and their inferred types
  </action>
  <verify>
    Run `cd backend && npx tsx -e "import { QuestionSchema, BatchSchema } from './src/scripts/content-generation/question-schema.js'; console.log('Schemas loaded OK')"` — should print "Schemas loaded OK" without errors. Verify zod, cheerio, p-limit appear in package.json dependencies.
  </verify>
  <done>Zod schemas validate question format, Anthropic client configured with prompt caching support, all 3 new dependencies installed.</done>
</task>

<task type="auto">
  <name>Task 2: Create locale configs, system prompt, and RAG fetcher</name>
  <files>
    backend/src/scripts/content-generation/prompts/system-prompt.ts
    backend/src/scripts/content-generation/locale-configs/bloomington-in.ts
    backend/src/scripts/content-generation/locale-configs/los-angeles-ca.ts
    backend/src/scripts/content-generation/rag/fetch-sources.ts
    backend/src/scripts/content-generation/rag/parse-sources.ts
  </files>
  <action>
    1. Create `prompts/system-prompt.ts`:
       - Export a function `buildSystemPrompt(localeName: string, topicDistribution: Record<string, number>)` that returns the system prompt string
       - Include instructions matching CONTEXT.md decisions:
         - Game-show tone matching federal questions
         - All distractors must be plausible local alternatives
         - Explanations cite source: "According to [source], ..."
         - Each question stands alone
         - Avoid partisan content (no political parties, controversial votes)
         - Stick to structural/factual civics
       - Difficulty distribution: Easy 40%, Medium 40%, Hard 20%
       - Source citation style: "According to bloomington.in.gov, the city council has 9 members."
       - For elected official questions: set expiresAt to term end date

    2. Create `locale-configs/bloomington-in.ts`:
       - Export `bloomingtonConfig` object with:
         - locale: 'bloomington-in'
         - name: 'Bloomington, Indiana'
         - externalIdPrefix: 'bli' (for bli-001, bli-002, etc.)
         - collectionSlug: 'bloomington-in' (matches existing seed data in collections.ts)
         - targetQuestions: 100
         - batchSize: 25
         - topicCategories: 5-8 categories derived from civic structure:
           - 'city-government' (~15 questions — mayor, city council, departments)
           - 'monroe-county' (~12 questions — commissioners, county services)
           - 'indiana-state' (~15 questions — governor, general assembly, state agencies)
           - 'civic-history' (~12 questions — founding, key events, IU's civic role)
           - 'local-services' (~12 questions — utilities, parks, public safety)
           - 'elections-voting' (~12 questions — local election process, districts)
           - 'landmarks-culture' (~10 questions — cultural institutions, notable places)
           - 'budget-finance' (~12 questions — city budget, tax structure)
         - sourceUrls: array of authoritative URLs to fetch:
           - https://bloomington.in.gov (city government)
           - https://www.co.monroe.in.us (Monroe County)
           - https://www.in.gov (Indiana state)
           - Additional .gov/.edu URLs for each topic area
         - topicDistribution: Record<string, number> mapping each category to target count

    3. Create `locale-configs/los-angeles-ca.ts`:
       - Export `losAngelesConfig` with same structure:
         - locale: 'los-angeles-ca'
         - name: 'Los Angeles, California'
         - externalIdPrefix: 'lac' (for lac-001, lac-002, etc.)
         - collectionSlug: 'los-angeles-ca'
         - targetQuestions: 100
         - batchSize: 25
         - topicCategories: 5-8 categories:
           - 'city-government' (~15 — mayor, city council 15 districts, departments)
           - 'la-county' (~12 — board of supervisors, county services)
           - 'california-state' (~15 — governor, legislature, propositions system)
           - 'civic-history' (~12 — founding, key events, growth)
           - 'local-services' (~12 — LADWP, Metro, public safety)
           - 'elections-voting' (~12 — local election process, neighborhood councils)
           - 'landmarks-culture' (~10 — cultural institutions, notable places)
           - 'budget-finance' (~12 — city budget, tax structure)
         - sourceUrls: authoritative LA URLs:
           - https://www.lacity.gov (city)
           - https://lacounty.gov (county)
           - https://www.ca.gov (state)

    4. Create `rag/fetch-sources.ts`:
       - Export async function `fetchSources(sourceUrls: string[], outputDir: string)`
       - For each URL: fetch with standard headers (User-Agent), handle redirects
       - Use cheerio to parse HTML and extract main content text (strip nav, footer, scripts, styles)
       - Save clean text to outputDir as `{slugified-domain}.txt`
       - Handle errors gracefully (log failed URLs, continue with others)
       - Use p-limit(3) for concurrent fetches

    5. Create `rag/parse-sources.ts`:
       - Export async function `loadSourceDocuments(sourceDir: string): Promise<string[]>`
       - Reads all .txt files from sourceDir
       - Returns array of document strings ready for prompt injection
       - Each document prefixed with filename for context
  </action>
  <verify>
    Run `cd backend && npx tsx -e "import { bloomingtonConfig } from './src/scripts/content-generation/locale-configs/bloomington-in.js'; import { losAngelesConfig } from './src/scripts/content-generation/locale-configs/los-angeles-ca.js'; console.log('BLI topics:', Object.keys(bloomingtonConfig.topicDistribution).length); console.log('LAC topics:', Object.keys(losAngelesConfig.topicDistribution).length)"` — should show 7-8 topics each.
  </verify>
  <done>Both locale configs define 5-8 topic categories with target question counts summing to ~100. System prompt encodes all CONTEXT.md decisions. RAG fetcher can download and parse .gov pages.</done>
</task>

<task type="auto">
  <name>Task 3: Create main generation script and database seeder</name>
  <files>
    backend/src/scripts/content-generation/utils/seed-questions.ts
    backend/src/scripts/content-generation/generate-locale-questions.ts
  </files>
  <action>
    1. Create `utils/seed-questions.ts`:
       - Import db from '../../db/index.js' (NOTE: relative path from scripts/content-generation/utils/)
       - Actually, import from the db module: Use path relative to the file location. The db index is at backend/src/db/index.ts. From utils/ that's '../../../db/index.js'
       - Import questions, collectionQuestions, topics, collections, collectionTopics from schema
       - Export async function `ensureLocaleTopics(collectionSlug: string, topicCategories: { slug: string, name: string, description: string }[]): Promise<Record<string, number>>`
         - Looks up the collection by slug
         - For each topic category: INSERT topic ON CONFLICT DO NOTHING, then link to collection via collection_topics
         - Returns topicIdMap: Record<topicSlug, topicId>
       - Export async function `seedQuestionBatch(batch: ValidatedQuestion[], collectionId: number, topicIdMap: Record<string, number>)`
         - For each question in batch:
           - Build NewQuestion object matching schema.ts types
           - Set status to 'draft' (admin reviews and activates)
           - Set expiresAt from question data (null if not applicable)
           - Set learningContent to null (not generating learning content initially)
           - INSERT into questions table ON CONFLICT (external_id) DO NOTHING
           - INSERT into collection_questions junction ON CONFLICT DO NOTHING
         - Log count of successfully seeded questions

    2. Create `generate-locale-questions.ts`:
       - Import dotenv/config at top
       - Parse CLI args: `--locale bloomington-in|los-angeles-ca` (required), `--batch N` (optional, default: all batches), `--fetch-sources` (optional flag to re-fetch RAG sources), `--dry-run` (optional, generate but don't seed)
       - Load locale config dynamically based on --locale argument
       - Main flow:
         a. If --fetch-sources flag: call fetchSources() with config's sourceUrls, save to `backend/src/scripts/data/sources/{locale}/`
         b. Load source documents from data/sources/{locale}/ using loadSourceDocuments()
         c. Calculate number of batches: Math.ceil(targetQuestions / batchSize)
         d. For each batch (or single batch if --batch specified):
            - Build system prompt with source documents using prompt caching (cache_control: { type: 'ephemeral' } on source doc blocks)
            - Call Anthropic API with temperature 0, max_tokens 8192
            - Parse JSON response and validate with BatchSchema.parse()
            - Display summary: count by difficulty, count by topic, any validation warnings
            - If not --dry-run: call seedQuestionBatch() to insert to database
            - Log cache performance (cache_creation_input_tokens vs cache_read_input_tokens)
         e. Print final summary: total questions generated, by topic, by difficulty
       - Error handling: wrap each batch in try/catch, log errors, continue to next batch
       - Usage examples in file header comment:
         ```
         npx tsx src/scripts/content-generation/generate-locale-questions.ts --locale bloomington-in --fetch-sources
         npx tsx src/scripts/content-generation/generate-locale-questions.ts --locale bloomington-in --batch 1 --dry-run
         npx tsx src/scripts/content-generation/generate-locale-questions.ts --locale los-angeles-ca
         ```
  </action>
  <verify>
    Run `cd backend && npx tsx src/scripts/content-generation/generate-locale-questions.ts --help 2>&1 || npx tsx -e "import './src/scripts/content-generation/generate-locale-questions.js'" 2>&1 | head -5` — script should load without import errors. Verify the file structure exists: `ls backend/src/scripts/content-generation/` should show all expected files and directories (anthropic-client.ts, question-schema.ts, prompts/, locale-configs/, rag/, utils/, generate-locale-questions.ts).
  </verify>
  <done>Main generation script loads locale config, fetches RAG sources, calls Anthropic API with prompt caching, validates output with Zod, and seeds to database with draft status. Script is invocable via CLI with --locale flag.</done>
</task>

</tasks>

<verification>
1. All files exist under backend/src/scripts/content-generation/ with correct directory structure
2. `npm ls zod cheerio p-limit` shows all three installed in backend/
3. Locale configs define topic categories summing to ~100 questions each
4. Zod schema matches database schema.ts question structure
5. Script can be invoked with `--locale bloomington-in` without import errors
</verification>

<success_criteria>
- Content generation tooling is a complete, reusable pipeline
- Both locale configs (Bloomington, LA) define 5-8 topic categories with source URLs
- Script accepts --locale, --batch, --fetch-sources, --dry-run flags
- Questions are validated against Zod schema before database insertion
- Prompt caching is configured for RAG source documents (cache_control: ephemeral)
- Database seeder inserts questions with status='draft' and links to correct collection
</success_criteria>

<output>
After completion, create `.planning/phases/17-community-content-generation/17-01-SUMMARY.md`
</output>
